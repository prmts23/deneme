# Troubleshooting Guide ğŸ”§

**YaygÄ±n hatalar ve Ã§Ã¶zÃ¼mleri**

---

## âŒ "ValueError: Found array with 0 sample(s)"

### Sebep:
Feature engineering sonrasÄ± tÃ¼m satÄ±rlar dropna() ile silindi.

### Ã‡Ã¶zÃ¼m 1: Data MiktarÄ±nÄ± Kontrol Edin
```bash
# En az 1000-2000 bar olmalÄ±
python test_system.py
```

En az **1000 bar** data olmalÄ±. Tercihen **10,000+**.

### Ã‡Ã¶zÃ¼m 2: Data Path'i Kontrol Edin
```python
# config.py
DATA_PATH = "/path/to/your/data.csv"  # âš ï¸  DoÄŸru path?
```

Dosya var mÄ±?
```bash
ls -la /path/to/your/data.csv
```

### Ã‡Ã¶zÃ¼m 3: CSV Format KontrolÃ¼
CSV ÅŸu sÃ¼tunlara sahip olmalÄ±:
```
timestamp, open, high, low, close, volume
```

Veya:
```
timestamp, Open, High, Low, Close, Volume
```

---

## âŒ "FileNotFoundError: [Errno 2] No such file or directory"

### Ã‡Ã¶zÃ¼m:
```python
# config.py'de absolute path kullanÄ±n
DATA_PATH = "/home/user/trading/AVAXUSDT_5m.csv"  # âœ… Good
DATA_PATH = "data/AVAXUSDT_5m.csv"  # âŒ Bad (relative)
```

**Windows'ta:**
```python
DATA_PATH = "C:/Users/YourName/data/AVAXUSDT_5m.csv"
# veya
DATA_PATH = r"C:\Users\YourName\data\AVAXUSDT_5m.csv"
```

---

## âŒ "KeyError: 'timestamp'"

### Sebep:
CSV'de timestamp kolonu yok veya farklÄ± isimde.

### Ã‡Ã¶zÃ¼m:
CSV'nizi kontrol edin:
```python
import pandas as pd
df = pd.read_csv('your_file.csv')
print(df.columns)
```

EÄŸer `date` veya baÅŸka bir isim varsa:
```python
# CSV'yi dÃ¼zeltin:
df.rename(columns={'date': 'timestamp'}, inplace=True)
df.to_csv('your_file.csv', index=False)
```

---

## âŒ "No signals generated" (target_long=0, target_short=0)

### Sebep:
Barrier'lar Ã§ok sÄ±kÄ±, hiÃ§bir trade TP'ye ulaÅŸamÄ±yor.

### Ã‡Ã¶zÃ¼m:
```python
# config.py - Barrier'larÄ± gevÅŸetin
STATIC_TP_PCT = 1.0  # 1.5'ten dÃ¼ÅŸÃ¼rÃ¼n
STATIC_SL_PCT = 0.8  # 1.0'dan dÃ¼ÅŸÃ¼rÃ¼n
MIN_RETURN_THRESHOLD = 0.2  # 0.3'ten dÃ¼ÅŸÃ¼rÃ¼n
```

Test edin:
```bash
python test_system.py
```

Signals gÃ¶rmelisiniz:
```
LONG signals: 450 (9.0%)
SHORT signals: 430 (8.6%)
```

**Optimal signal oranÄ±: %5-15**

---

## âŒ "Overfitting: Train F1=0.95, Test F1=0.55"

### Sebep:
Model training data'yÄ± ezberliyor.

### Ã‡Ã¶zÃ¼m 1: Feature SayÄ±sÄ±nÄ± AzaltÄ±n
```python
# config.py
TOP_N_FEATURES = 30  # 50'den azaltÄ±n
```

### Ã‡Ã¶zÃ¼m 2: Regularization ArtÄ±rÄ±n
Optuna otomatik yapÄ±yor ama manuel de ayarlayabilirsiniz:
```python
# model_training.py
params = {
    'max_depth': 4,  # 6'dan azaltÄ±n
    'min_child_weight': 5,  # ArtÄ±rÄ±n
    'gamma': 2.0,  # ArtÄ±rÄ±n
}
```

### Ã‡Ã¶zÃ¼m 3: Daha Fazla Data
En az 50,000 bar kullanÄ±n.

---

## âŒ "Train/Test performance Ã§ok dÃ¼ÅŸÃ¼k (F1 < 0.55)"

### Sebep 1: KÃ¶tÃ¼ Labeling
Asset'inizin volatilitesine gÃ¶re barrier'lar yanlÄ±ÅŸ ayarlanmÄ±ÅŸ.

**Ã‡Ã¶zÃ¼m:**
```python
# YÃ¼ksek volatilite (BTC, altcoin) iÃ§in:
STATIC_TP_PCT = 2.0
STATIC_SL_PCT = 1.5

# DÃ¼ÅŸÃ¼k volatilite (major forex, stablecoin) iÃ§in:
STATIC_TP_PCT = 0.5
STATIC_SL_PCT = 0.3
```

### Sebep 2: Data Quality
NaN, zero volume, duplicate candles?

**Ã‡Ã¶zÃ¼m:**
```python
# Data temizleme
df = df[df['volume'] > 0]  # SÄ±fÄ±r volume'leri at
df = df.drop_duplicates(subset=['timestamp'])  # DuplikatlarÄ± at
df = df.dropna()  # NaN'larÄ± at
```

---

## âŒ "SMOTE Error: k_neighbors too large"

### Sebep:
Positive class Ã§ok az (< 6 sample).

### Ã‡Ã¶zÃ¼m:
```python
# config.py
USE_SMOTE = False  # SMOTE'u devre dÄ±ÅŸÄ± bÄ±rakÄ±n

# Veya barrier'larÄ± gevÅŸetin (daha fazla signal)
MIN_RETURN_THRESHOLD = 0.2
```

---

## âŒ "Optuna Ã§ok yavaÅŸ / dondu"

### Ã‡Ã¶zÃ¼m 1: Trial SayÄ±sÄ±nÄ± AzaltÄ±n
```python
# config.py
OPTUNA_TRIALS = 20  # 100'den azaltÄ±n (test iÃ§in)
```

### Ã‡Ã¶zÃ¼m 2: Optuna'yÄ± Devre DÄ±ÅŸÄ± BÄ±rakÄ±n (Ä°lk Testler)
```python
# config.py
USE_OPTUNA = False  # Default parameters kullan
```

Sonra production iÃ§in aÃ§Ä±n.

---

## âŒ "ImportError: No module named 'optuna'"

### Ã‡Ã¶zÃ¼m:
```bash
pip install -r requirements.txt

# Veya manuel:
pip install optuna xgboost lightgbm catboost ta imbalanced-learn
```

---

## âŒ "Memory Error / Killed"

### Sebep:
Ã‡ok fazla data + Ã§ok fazla feature = RAM doldu.

### Ã‡Ã¶zÃ¼m 1: Data AzaltÄ±n (Test Ä°Ã§in)
```python
# train_advanced.py baÅŸÄ±nda:
df = pd.read_csv(DATA_PATH)
df = df.tail(20000)  # Son 20K bar ile test
```

### Ã‡Ã¶zÃ¼m 2: Feature AzaltÄ±n
```python
# config.py
TOP_N_FEATURES = 30  # 50'den azalt
```

### Ã‡Ã¶zÃ¼m 3: Daha Az Model
```python
# config.py
MODELS = {
    'xgboost': True,
    'lightgbm': False,  # Devre dÄ±ÅŸÄ±
    'catboost': False,  # Devre dÄ±ÅŸÄ±
}
```

---

## âŒ "Walk-Forward results Ã§ok kÃ¶tÃ¼"

### Sebep:
Model regime change'lere adapt olamÄ±yor.

### Ã‡Ã¶zÃ¼m 1: Window Size AzaltÄ±n
```python
# config.py
WALK_FORWARD_WINDOW = 5000  # 10000'den azaltÄ±n
WALK_FORWARD_STEP = 1000  # 2000'den azaltÄ±n
```

Daha sÄ±k retrain = daha iyi adaptation.

### Ã‡Ã¶zÃ¼m 2: Regime Features Ekleyin
Zaten var ama ADX, Hurst gibi features'lara extra aÄŸÄ±rlÄ±k verin.

---

## âŒ "Freqtrade entegrasyon hatasÄ±"

### Ã‡Ã¶zÃ¼m:
```python
# freqtrade_strategy_example.py
model_dir = '/FULL/PATH/TO/ml_trading_advanced/models_advanced'

# PATH'e ekleyin:
import sys
sys.path.append('/FULL/PATH/TO/ml_trading_advanced')
```

**Test edin:**
```bash
freqtrade backtesting --strategy MLAdvancedStrategy --timeframe 5m
```

---

## ğŸ” Genel Debugging AdÄ±mlarÄ±

### 1. Test System
```bash
python test_system.py
```

Bu script:
- âœ… Config kontrolÃ¼
- âœ… Data yÃ¼kleme
- âœ… Feature engineering test
- âœ… Labeling test
- âœ… HatalarÄ± gÃ¶sterir

### 2. Check Data
```python
import pandas as pd

df = pd.read_csv('your_file.csv')
print(f"Rows: {len(df)}")
print(f"Columns: {list(df.columns)}")
print(f"NaNs: {df.isna().sum().sum()}")
print(f"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}")
```

### 3. KÃ¼Ã§Ã¼k Sample Test
```python
# train_advanced.py'de:
df = df.tail(5000)  # Sadece son 5K bar

# config.py'de:
USE_OPTUNA = False
OPTUNA_TRIALS = 10
```

HÄ±zlÄ± test â†’ HatayÄ± bul â†’ DÃ¼zelt â†’ Full training

---

## ğŸ’¡ Performance Ä°yileÅŸtirme

### Test F1 < 0.60 ise:

1. **Barrier'larÄ± ayarlayÄ±n**
   ```python
   # Volatiliteyi hesaplayÄ±n:
   df['atr'] = df['high'] - df['low']
   avg_atr_pct = (df['atr'] / df['close']).mean() * 100
   print(f"Average ATR: {avg_atr_pct:.2f}%")

   # TP'yi ATR'nin 2-3 katÄ± yapÄ±n:
   STATIC_TP_PCT = avg_atr_pct * 2.5
   ```

2. **Feature selection**
   ```bash
   # Training sonrasÄ±:
   cat models_advanced/feature_importance_initial.csv
   ```

   En Ã¶nemli 20 feature'a bakÄ±n. Noise var mÄ±?

3. **Threshold optimization**
   ```python
   import pandas as pd
   from sklearn.metrics import f1_score

   preds = pd.read_csv('models_advanced/walk_forward_predictions_long.csv')

   for t in [0.45, 0.50, 0.55, 0.60, 0.65, 0.70]:
       y_pred = (preds['y_pred_proba'] >= t).astype(int)
       f1 = f1_score(preds['y_true'], y_pred)
       print(f"Threshold {t:.2f}: F1 = {f1:.3f}")
   ```

---

## ğŸ“ HÃ¢lÃ¢ Ã‡alÄ±ÅŸmÄ±yor?

### Checklist:
- [ ] Data dosyasÄ± var mÄ±? (`ls your_file.csv`)
- [ ] En az 1000 bar var mÄ±? (`wc -l your_file.csv`)
- [ ] CSV formatÄ± doÄŸru mu? (timestamp, OHLCV)
- [ ] `test_system.py` baÅŸarÄ±lÄ± mÄ±?
- [ ] Dependencies kurulu mu? (`pip list | grep xgboost`)
- [ ] Python 3.8+ mÄ±? (`python --version`)

### Debug Mode:
```python
# train_advanced.py baÅŸÄ±na ekleyin:
import warnings
warnings.filterwarnings('default')  # TÃ¼m uyarÄ±larÄ± gÃ¶ster

import traceback
import sys

try:
    # ... kod ...
except Exception as e:
    traceback.print_exc()
    sys.exit(1)
```

---

## âœ… BaÅŸarÄ± Kriterleri

Sistem Ã§alÄ±ÅŸÄ±yor demektir:
- âœ… `test_system.py` baÅŸarÄ±lÄ±
- âœ… Training hatasÄ±z tamamlanÄ±yor
- âœ… Test F1 > 0.60
- âœ… Train/Test farkÄ± < %20
- âœ… Walk-forward ortalama F1 > 0.55
- âœ… Signals %5-15 arasÄ±

Bu deÄŸerlere ulaÅŸtÄ±ysanÄ±z â†’ Paper trading!

---

**BaÅŸka sorun?** README.md'ye bakÄ±n veya issue aÃ§Ä±n.
