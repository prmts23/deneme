# Quick Start Guide ğŸš€

**5 dakikada ML Trading sistemini Ã§alÄ±ÅŸtÄ±rÄ±n!**

## 1ï¸âƒ£ Kurulum (2 dakika)

```bash
cd ml_trading_advanced
pip install -r requirements.txt
```

## 2ï¸âƒ£ KonfigÃ¼rasyon (1 dakika)

`config.py` dosyasÄ±nÄ± dÃ¼zenleyin:

```python
# DATA_PATH - CSV dosyanÄ±zÄ±n yolunu girin
DATA_PATH = "/content/AVAXUSDT_5m_ALL_YEARS.csv"

# DiÄŸer ayarlar varsayÄ±lan olarak iyidir
```

### CSV Format

CSV dosyanÄ±z ÅŸu sÃ¼tunlara sahip olmalÄ±:
```
timestamp, open, high, low, close, volume
```

Veya:
```
timestamp, Open, High, Low, Close, Volume
```

## 3ï¸âƒ£ Training (2 dakika - 2 saat, data boyutuna gÃ¶re)

```bash
python train_advanced.py
```

### Beklenen Ã‡Ä±ktÄ±:

```
================================================================================
ADVANCED ML TRADING STRATEGY - TRAINING PIPELINE
================================================================================

STEP 1: LOADING DATA
âœ“ Data loaded: 150,000 bars

STEP 2: FEATURE ENGINEERING
ğŸ”§ Engineering advanced features...
   âœ“ Time features added
   âœ“ Price action features added
   âœ“ Volume features added
   ...
âœ“ Features engineered. Rows: 149,800

STEP 3: CREATING LABELS (TRIPLE BARRIER METHOD)
ğŸ·ï¸  Creating labels using Triple Barrier Method (both)...
   Long labels created: 15,234 signals (10.17%)
   Short labels created: 14,987 signals (10.00%)

STEP 4: PREPARING FEATURES
Total features: 237
Performing feature selection to get TOP 50 features...
âœ“ Selected 50 features

STEP 5: TRAINING MODELS
================================================================================
TRAINING LONG MODELS
================================================================================

Training XGBOOST Model
Train samples: 74,860 (Class 1: 7,234, 9.7%)
Val samples:   22,470 (Class 1: 2,187, 9.7%)
Test samples:  52,470 (Class 1: 5,813, 11.1%)

Optimizing hyperparameters with Optuna...
[I 2024-XX-XX ...] Trial 0 finished with value: 0.7234
[I 2024-XX-XX ...] Trial 1 finished with value: 0.7456
...
Best AUC: 0.7821
Best params: {'n_estimators': 347, 'max_depth': 7, ...}

Train  | Acc: 0.892 | Prec: 0.847 | Rec: 0.823 | F1: 0.835 | AUC: 0.934
Val    | Acc: 0.743 | Prec: 0.712 | Rec: 0.698 | F1: 0.705 | AUC: 0.782
Test   | Acc: 0.738 | Prec: 0.709 | Rec: 0.691 | F1: 0.700 | AUC: 0.776

ğŸ† Best LONG model: XGBOOST
   Test F1: 0.700
   Test AUC: 0.776

STEP 6: WALK-FORWARD VALIDATION
...

âœ… ALL DONE! Models are ready for deployment.
```

## 4ï¸âƒ£ SonuÃ§larÄ± Ä°nceleme

```bash
ls models_advanced/

# Ã‡Ä±ktÄ±:
# model_long_xgboost.pkl
# model_short_xgboost.pkl
# scaler_long_xgboost.pkl
# scaler_short_xgboost.pkl
# features.txt
# walk_forward_long.csv
# walk_forward_short.csv
# feature_importance_initial.csv
```

### Walk-Forward SonuÃ§larÄ±na BakÄ±n:

```python
import pandas as pd

wf = pd.read_csv('models_advanced/walk_forward_long.csv')
print(wf[['fold', 'f1', 'precision', 'recall', 'roc_auc']])

#    fold    f1  precision  recall  roc_auc
# 0     1  0.68       0.71    0.66     0.75
# 1     2  0.72       0.74    0.70     0.78
# 2     3  0.65       0.69    0.62     0.72
# ...

print(f"Average F1: {wf['f1'].mean():.3f}")
print(f"Average AUC: {wf['roc_auc'].mean():.3f}")
```

## 5ï¸âƒ£ Inference (Tahmin Yapma)

```python
from inference import TradingPredictor
import pandas as pd

# Veri yÃ¼kle
df = pd.read_csv('/content/AVAXUSDT_5m_ALL_YEARS.csv')

# Predictor oluÅŸtur
predictor = TradingPredictor(model_dir='models_advanced')

# En son bar iÃ§in tahmin
signal = predictor.predict_latest(
    df,
    side='both',
    long_threshold=0.65,
    short_threshold=0.65
)

print(f"Signal: {signal['signal']}")  # 1=LONG, -1=SHORT, 0=NEUTRAL
print(f"LONG prob: {signal['long_prob']:.3f}")
print(f"SHORT prob: {signal['short_prob']:.3f}")
```

---

## ğŸ¯ Ä°lk SonuÃ§lar KÃ¶tÃ¼yse?

### 1. Barrier'larÄ± AyarlayÄ±n

`config.py`:
```python
# Daha fazla sinyal istiyorsanÄ±z:
STATIC_TP_PCT = 1.0  # 1.5'ten 1.0'a dÃ¼ÅŸÃ¼rÃ¼n
MIN_RETURN_THRESHOLD = 0.2  # 0.3'ten 0.2'ye dÃ¼ÅŸÃ¼rÃ¼n

# Daha kaliteli sinyal istiyorsanÄ±z:
STATIC_TP_PCT = 2.0  # 1.5'ten 2.0'a Ã§Ä±karÄ±n
MIN_RETURN_THRESHOLD = 0.5  # 0.3'ten 0.5'e Ã§Ä±karÄ±n
```

### 2. Feature SayÄ±sÄ±nÄ± DeÄŸiÅŸtirin

```python
TOP_N_FEATURES = 40  # 50'den 40'a dÃ¼ÅŸÃ¼rÃ¼n (overfitting'i azaltÄ±r)
# veya
TOP_N_FEATURES = 70  # 50'den 70'e Ã§Ä±karÄ±n (daha fazla bilgi)
```

### 3. Optuna'yÄ± AtlayÄ±n (HÄ±zlÄ± Test)

```python
USE_OPTUNA = False  # Ä°lk testler iÃ§in
# Sonra True yapÄ±p optimize edin
```

### 4. Daha Fazla Data

- En az 50,000 bar kullanÄ±n
- Tercihen 100,000+ bar

### 5. FarklÄ± Asset Deneyin

- Volatilite yÃ¼ksek â†’ BTC, ETH daha iyi
- Volatilite dÃ¼ÅŸÃ¼k â†’ Stablecoin pair'ler zor

---

## ğŸ“Š Benchmark SonuÃ§lar (AVAXUSDT 5m)

| Metric | Target | Good | Excellent |
|--------|--------|------|-----------|
| Test F1 | >0.60 | >0.70 | >0.80 |
| Test AUC | >0.70 | >0.75 | >0.85 |
| Precision | >0.60 | >0.70 | >0.80 |
| Recall | >0.50 | >0.65 | >0.75 |

**Not**: Test ve Train arasÄ±nda Ã§ok fark varsa (Ã¶rn. Train F1=0.95, Test F1=0.60) â†’ Overfitting var!

---

## ğŸ”¥ Pro Tips

### Tip 1: Threshold Optimization
```python
# models_advanced/walk_forward_predictions_long.csv dosyasÄ±nÄ± kullanarak:
import pandas as pd
import numpy as np
from sklearn.metrics import f1_score, precision_score

preds = pd.read_csv('models_advanced/walk_forward_predictions_long.csv')

# FarklÄ± threshold'larÄ± test et
for threshold in np.arange(0.45, 0.80, 0.05):
    y_pred = (preds['y_pred_proba'] >= threshold).astype(int)
    f1 = f1_score(preds['y_true'], y_pred)
    prec = precision_score(preds['y_true'], y_pred)
    print(f"Threshold {threshold:.2f}: F1={f1:.3f}, Precision={prec:.3f}")

# En iyi threshold'u seÃ§
```

### Tip 2: Feature Importance
```python
import pandas as pd

imp = pd.read_csv('models_advanced/feature_importance_initial.csv')
print(imp.head(20))

# En Ã¶nemli feature'larÄ± not edin
# EÄŸer 'price_vs_sma_50' Ã§ok Ã¶nemliyse â†’ Trend following Ã§alÄ±ÅŸÄ±yor
# EÄŸer 'volatility_10' Ã§ok Ã¶nemliyse â†’ Volatility breakout Ã§alÄ±ÅŸÄ±yor
```

### Tip 3: Model Comparison
```python
# FarklÄ± modelleri karÅŸÄ±laÅŸtÄ±rÄ±n
# config.py:
MODELS = {
    'xgboost': True,
    'lightgbm': True,
    'catboost': True,
}

# Training sonrasÄ± en iyi performansÄ± seÃ§in
```

---

## âš¡ HÄ±zlÄ± Test (1 dakika)

Tam training Ã§ok uzun sÃ¼rÃ¼yorsa, kÃ¼Ã§Ã¼k bir subset ile test edin:

```python
# train_advanced.py'de bu satÄ±rÄ± bulun:
df = pd.read_csv(data_path)

# Hemen altÄ±na ekleyin:
df = df.tail(20000)  # Son 20K bar ile test

# config.py'de:
USE_OPTUNA = False
OPTUNA_TRIALS = 20  # 100 yerine
```

---

## â“ SÄ±k Sorulan Sorular

**S: Training ne kadar sÃ¼rer?**
A:
- 50K bar, Optuna=False: ~2-5 dakika
- 50K bar, Optuna=True, 100 trials: ~20-40 dakika
- 200K bar, Optuna=True: ~1-2 saat

**S: Test F1 0.50 civarÄ±nda, normal mi?**
A: HayÄ±r, Ã§ok dÃ¼ÅŸÃ¼k. Barrier'larÄ± ve MIN_RETURN_THRESHOLD'u ayarlayÄ±n.

**S: Train F1=0.95, Test F1=0.60, sorun ne?**
A: Overfitting. TOP_N_FEATURES azaltÄ±n (30-40), regularization artÄ±rÄ±n.

**S: Optuna gerekli mi?**
A: Ä°lk testlerde hayÄ±r. Ancak production iÃ§in kesinlikle evet.

**S: LONG iyi, SHORT kÃ¶tÃ¼?**
A: Normal. Crypto genelde uptrend. SHORT'u devre dÄ±ÅŸÄ± bÄ±rakabilirsiniz.

---

**BaÅŸarÄ±lar! ğŸ“ˆğŸš€**

Sorun olursa README.md'ye bakÄ±n veya issue aÃ§Ä±n.
